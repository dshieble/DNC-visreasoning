{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/numeric.py:190: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  a = empty(shape, dtype, order)\n",
      "dnc/utility.py:297: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  stamp1[upper_left_corner1[0]:upper_left_corner1[0] + square_side1 , upper_left_corner1[1]:upper_left_corner1[1] + square_side1] = square1\n",
      "dnc/utility.py:298: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  stamp2[upper_left_corner2[0]:upper_left_corner2[0] + square_side2 , upper_left_corner2[1]:upper_left_corner2[1] + square_side2] = square2\n",
      "dnc/utility.py:266: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  canvas[upper_left_corner[0]:upper_left_corner[0] + square_side , upper_left_corner[1]:upper_left_corner[1] + square_side] = square\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py:29: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  return umr_minimum(a, axis, None, out, keepdims)\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:47<00:00,  3.06s/it]12%|█▎        | 2/16 [00:05<00:40,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing...\n",
      "computing gradients...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:00<?, ?it/s]100%|██████████| 17/17 [00:00<00:00, 198.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying gradients...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized!\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Blas SGEMM launch failed : a.shape=(10, 586), b.shape=(586, 256), m=10, n=256, k=586\n\t [[Node: controller/shape_inference/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](controller/shape_inference/MatMul/a, controller/layer1_W/read)]]\n\t [[Node: sequence_loop/TopKV2_5/k/_361 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_29185_sequence_loop/TopKV2_5/k\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op u'controller/shape_inference/MatMul', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-ef55744406ea>\", line 114, in <module>\n    batch_size=params[\"bsize\"]\n  File \"dnc/dnc.py\", line 44, in __init__\n    **controller_params)\n  File \"basic_recurrent_controller.py\", line 18, in __init__\n    memory_word_size, sequence_length, batch_size=batch_size)\n  File \"dnc/controller.py\", line 49, in __init__\n    nn_output_size = self.get_nn_output_size()\n  File \"dnc/controller.py\", line 104, in get_nn_output_size\n    output_vector,_ = self.network_op(input_vector, self.get_state(), t=0)\n  File \"basic_recurrent_controller.py\", line 37, in network_op\n    l1_output = tf.matmul(X, self.W1) + self.b1\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 1729, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1442, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(10, 586), b.shape=(586, 256), m=10, n=256, k=586\n\t [[Node: controller/shape_inference/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](controller/shape_inference/MatMul/a, controller/layer1_W/read)]]\n\t [[Node: sequence_loop/TopKV2_5/k/_361 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_29185_sequence_loop/TopKV2_5/k\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ef55744406ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m         feed_dict={\n\u001b[1;32m    146\u001b[0m             \u001b[0mncomputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mncomputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_output\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTarget_Output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         })\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas SGEMM launch failed : a.shape=(10, 586), b.shape=(586, 256), m=10, n=256, k=586\n\t [[Node: controller/shape_inference/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](controller/shape_inference/MatMul/a, controller/layer1_W/read)]]\n\t [[Node: sequence_loop/TopKV2_5/k/_361 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_29185_sequence_loop/TopKV2_5/k\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op u'controller/shape_inference/MatMul', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-ef55744406ea>\", line 114, in <module>\n    batch_size=params[\"bsize\"]\n  File \"dnc/dnc.py\", line 44, in __init__\n    **controller_params)\n  File \"basic_recurrent_controller.py\", line 18, in __init__\n    memory_word_size, sequence_length, batch_size=batch_size)\n  File \"dnc/controller.py\", line 49, in __init__\n    nn_output_size = self.get_nn_output_size()\n  File \"dnc/controller.py\", line 104, in get_nn_output_size\n    output_vector,_ = self.network_op(input_vector, self.get_state(), t=0)\n  File \"basic_recurrent_controller.py\", line 37, in network_op\n    l1_output = tf.matmul(X, self.W1) + self.b1\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 1729, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1442, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(10, 586), b.shape=(586, 256), m=10, n=256, k=586\n\t [[Node: controller/shape_inference/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](controller/shape_inference/MatMul/a, controller/layer1_W/read)]]\n\t [[Node: sequence_loop/TopKV2_5/k/_361 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_29185_sequence_loop/TopKV2_5/k\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from dnc.dnc import DNC\n",
    "import dnc.utility as uf\n",
    "from tqdm import tqdm\n",
    "from feedforward_controller import FeedforwardController\n",
    "from basic_recurrent_controller import BasicRecurrentController\n",
    "from focus_recurrent_controller import FocusRecurrentController\n",
    "from spotlight_recurrent_controller import SpotlightRecurrentController\n",
    "import time\n",
    "from feedforward_controller import FeedforwardController\n",
    "from basic_recurrent_controller import BasicRecurrentController\n",
    "from focus_recurrent_controller import FocusRecurrentController\n",
    "from spotlight_recurrent_controller import SpotlightRecurrentController\n",
    "from circle_recurrent_controller import CircularSpotlightRecurrentController\n",
    "\n",
    "\n",
    "cifs_path = \"/media/data_cifs/DNC_Visual_Reasoning_Results_Logs\"\n",
    "\n",
    "\n",
    "#Remove logging  from previous training runs\n",
    "os.system(\"rm {}/*.npy\".format(cifs_path))\n",
    "\n",
    "#Parameters of the task and the training\n",
    "params = {}\n",
    "params[\"timestamp\"] = str(int(time.time())) #the  identifier for this test run\n",
    "params[\"task\"] = \"2_square_detect\" #specify the task\n",
    "params[\"num_iter\"] = 20000 #the number of batches to run\n",
    "params[\"bsize\"] = 10 #the batch size\n",
    "params[\"input_side\"] = 24 #the length of each side of each image\n",
    "params[\"input_size\"] = params[\"input_side\"]**2 #the number of pixels\n",
    "params[\"num_labels\"] = 2 #the number of labels\n",
    "params[\"sequence_length\"] = 16 #the number of images in the sequence\n",
    "params[\"half_max_item\"] = 3 #parameter for sd task; Note: if this changes, then so should *sigma_max* in spotlight_recurrent_controller.py\n",
    "params[\"memory_words_num\"] = 10 #the number of memory words\n",
    "params[\"memory_word_size\"] = 10#the size of memory words\n",
    "params[\"memory_read_heads\"] = 1 #the number of read heads\n",
    "params[\"print_step\"] = 500 #the number of steps between each loss printintg\n",
    "params[\"save_step\"] = 4000 # the number of steps between each save\n",
    "params[\"device\"] = \"/gpu:0\" #Set this to /gpu:0 or /gpu:1 etc if you want to use the gpu instead\n",
    "params[\"focus_type\"] = \"none\"\n",
    "params[\"loss_type\"] = \"all_steps\"\n",
    "\n",
    "params[\"item_position\"] = \"random\" # fixed or random; controls location of items in square_detect, 2_square_detect and sd tasks\n",
    "params[\"item_size\"] = \"random\"     # \"\"; controls size \"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Import correct controller and define attention attributes\n",
    "if params[\"focus_type\"] == \"none\":\n",
    "    ctrlr = BasicRecurrentController\n",
    "    get_attributes = lambda c: ([c.W1], [c.W2], [c.W3])\n",
    "    attr1 = \"W1\"\n",
    "    attr2 = \"W2\"\n",
    "    attr3 = \"W3\"\n",
    "elif params[\"focus_type\"] == \"mask\" or params[\"focus_type\"] == \"rowcol\":\n",
    "    ctrlr = FocusRecurrentController\n",
    "    get_attributes = lambda c: (c.focus_row, c.focus_col, c.focus_mask)\n",
    "elif params[\"focus_type\"] == \"spotlight\":\n",
    "    ctrlr =  SpotlightRecurrentController\n",
    "    get_attributes = lambda c: (c.spotlight_row, c.spotlight_col, c.spotlight_sigma)\n",
    "elif params[\"focus_type\"] == \"circular_spotlight\":\n",
    "    ctrlr = CircularSpotlightRecurrentController\n",
    "    get_attributes = lambda c: (c.spotlight_row, c.spotlight_col, c.spotlight_radius)\n",
    "\n",
    "# Set loss function\n",
    "\n",
    "# Loss at all time steps\n",
    "if params[\"loss_type\"] == \"all_steps\": \n",
    "    params[\"loss_weightings\"] = np.ones(params[\"sequence_length\"])\n",
    "\n",
    "# Loss at last timestep     \n",
    "elif params[\"loss_type\"] == \"last_step\":\n",
    "    params[\"loss_weightings\"] = np.array([i == (params[\"sequence_length\"] - 1) for i in range(params[\"sequence_length\"])])  \n",
    "\n",
    "# Loss increasing by timestep\n",
    "elif params[\"loss_type\"] == \"increasing\": \n",
    "    params[\"loss_weightings\"] = np.arange(params[\"sequence_length\"]) \n",
    "\n",
    "assert len(params[\"loss_weightings\"]) == params[\"sequence_length\"], (\"Length of loss weights must be equal to sequence length\")\n",
    "\n",
    "#Test\n",
    "_, _ = uf.make_ims(params)\n",
    "\n",
    "\n",
    "#Make the directory for this run of the algorithm and save the params to it\n",
    "\n",
    "os.system(\"mkdir -p {}/{}\".format(cifs_path, params[\"timestamp\"]))\n",
    "os.system(\"cp DNC_Visual_Reasoning.py {}/{}/DNC_Visual_Reasoning_snapshot.py\".format(cifs_path, params[\"timestamp\"]))\n",
    "np.save(\"{}/{}/params.npy\".format(cifs_path, params[\"timestamp\"]), params)\n",
    "\n",
    "\n",
    "#Reset the graph and run the algorithm\n",
    "tf.reset_default_graph()\n",
    "with tf.device(params[\"device\"]):\n",
    "    sess = tf.InteractiveSession(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "  \n",
    "    #build the neural computer\n",
    "    ncomputer = DNC(\n",
    "        ctrlr,\n",
    "        input_size=params[\"input_size\"],\n",
    "        output_size=params[\"num_labels\"],\n",
    "        sequence_length=params[\"sequence_length\"],\n",
    "        controller_params={\"focus_type\":params[\"focus_type\"]},\n",
    "        memory_words_num=params[\"memory_words_num\"],\n",
    "        memory_word_size=params[\"memory_word_size\"],\n",
    "        memory_read_heads=params[\"memory_read_heads\"],\n",
    "        batch_size=params[\"bsize\"]\n",
    "    )\n",
    "    attr1, attr2, attr3 = get_attributes(ncomputer.controller)\n",
    "    output, loss = ncomputer.get_elementwise_loss(params[\"loss_weightings\"]) \n",
    "    \n",
    "    print \"initializing...\"\n",
    "    updt, grads = uf.get_updt(loss)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print \"initialized!\"\n",
    "\n",
    "    loss_vals = []\n",
    "    input_vals = []\n",
    "    output_vals = []\n",
    "    target_vals = []\n",
    "    view_vals = []\n",
    "    attributes = []\n",
    "    mem = []\n",
    "       \n",
    "for i in tqdm(range(params[\"num_iter\"])):\n",
    "\n",
    "    #Get the data and expected output for this batch\n",
    "    Input, Target_Output = uf.make_ims(params)\n",
    "\n",
    "    #Run the  update step\n",
    "\n",
    "    OUT = sess.run([\n",
    "    loss,\n",
    "    output,\n",
    "    ncomputer.packed_memory_view,\n",
    "    updt] +  attr1 + attr2 + attr3, \n",
    "    feed_dict={\n",
    "        ncomputer.input_data: Input,\n",
    "        ncomputer.target_output: Target_Output\n",
    "    })\n",
    "\n",
    "    l, o, v = OUT[:3]\n",
    "    out_attr1 = OUT[4:4 + len(attr1)]\n",
    "    out_attr2 = OUT[4 + len(attr1):4 + len(attr1) + len(attr2)]\n",
    "    out_attr3 = OUT[4 + len(attr1) +  len(attr2):4 + len(attr1) + len(attr2) + len(attr3)]\n",
    "\n",
    "\n",
    "    #Keep track of the values at this timestep\n",
    "    loss_vals.append(l)\n",
    "    input_vals.append(Input)\n",
    "    output_vals += list(o)\n",
    "    view_vals.append(v)\n",
    "    target_vals += list(Target_Output)\n",
    "    mem.append(ncomputer.packed_memory_view)\n",
    "    attributes.append((np.array(out_attr1), np.array(out_attr2), np.array(out_attr3)))\n",
    "\n",
    "    #Print the loss and accuracy thus far\n",
    "    if len(target_vals) % params[\"print_step\"] == 0 and len(target_vals) > 0:\n",
    "        print \"np.array(target_vals).shape\", np.array(target_vals).shape\n",
    "        print \"np.array(output_vals).shape\", np.array(output_vals).shape\n",
    "\n",
    "        losses = {}\n",
    "        losses[\"loss\"] = np.mean(loss_vals[-params[\"print_step\"]:])\n",
    "        losses[\"matches\"] = np.mean(np.argmax(np.array(output_vals)[-params[\"print_step\"]:, -1], -1) == \n",
    "                                 np.argmax(np.array(target_vals)[-params[\"print_step\"]:, -1], -1))\n",
    "\n",
    "        print \"loss\", losses[\"loss\"]\n",
    "        print \"matches\", losses[\"matches\"]\n",
    "\n",
    "        np.save(\"{}/{}/losses_{}.npy\".format(cifs_path, params[\"timestamp\"], i), losses)\n",
    "\n",
    "    #Save the model and the masks generated\n",
    "    if len(target_vals) % params[\"save_step\"] == 0 and len(target_vals) > 0:\n",
    "        print \"saving for {}\".format(i)\n",
    "        np.save(\"{}/{}/outputs_{}.npy\".format(cifs_path, params[\"timestamp\"], i), output_vals[-50:])\n",
    "        np.save(\"{}/{}/targets_{}.npy\".format(cifs_path, params[\"timestamp\"], i), target_vals[-50:])\n",
    "        np.save(\"{}/{}/inputs_{}.npy\".format(cifs_path, params[\"timestamp\"], i), input_vals[-50:])\n",
    "        np.save(\"{}/{}/attributes_{}.npy\".format(cifs_path, params[\"timestamp\"], i), attributes[-50:])\n",
    "\n",
    "        #Save the weights of the model - disabled because the model checkpoints are big and bulky \n",
    "        # ncomputer.save(sess, \n",
    "        #                \"{}/{}\".format(params[\"timestamp\"]), cifs_path, \n",
    "        #                \"saved_weights_{}.npy\".format(i))\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/20000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in tqdm(range(params[\"num_iter\"])):\n",
    "\n",
    "    #Get the data and expected output for this batch\n",
    "    Input, Target_Output = uf.make_ims(params)\n",
    "\n",
    "    #Run the  update step\n",
    "\n",
    "    OUT = sess.run([\n",
    "    loss,\n",
    "    output,\n",
    "    ncomputer.packed_memory_view,\n",
    "    updt] +  attr1 + attr2 + attr3, \n",
    "    feed_dict={\n",
    "        ncomputer.input_data: Input,\n",
    "        ncomputer.target_output: Target_Output\n",
    "    })\n",
    "\n",
    "    l, o, v = OUT[:3]\n",
    "    out_attr1 = OUT[4:4 + len(attr1)]\n",
    "    out_attr2 = OUT[4 + len(attr1):4 + len(attr1) + len(attr2)]\n",
    "    out_attr3 = OUT[4 + len(attr1) +  len(attr2):4 + len(attr1) + len(attr2) + len(attr3)]\n",
    "\n",
    "\n",
    "    #Keep track of the values at this timestep\n",
    "    loss_vals.append(l)\n",
    "    input_vals.append(Input)\n",
    "    output_vals += list(o)\n",
    "    view_vals.append(v)\n",
    "    target_vals += list(Target_Output)\n",
    "    mem.append(ncomputer.packed_memory_view)\n",
    "    attributes.append((np.array(out_attr1), np.array(out_attr2), np.array(out_attr3)))\n",
    "\n",
    "    #Print the loss and accuracy thus far\n",
    "    if len(target_vals) % params[\"print_step\"] == 0 and len(target_vals) > 0:\n",
    "        print \"np.array(target_vals).shape\", np.array(target_vals).shape\n",
    "        print \"np.array(output_vals).shape\", np.array(output_vals).shape\n",
    "\n",
    "        losses = {}\n",
    "        losses[\"loss\"] = np.mean(loss_vals[-params[\"print_step\"]:])\n",
    "        losses[\"matches\"] = np.mean(np.argmax(np.array(output_vals)[-params[\"print_step\"]:, -1], -1) == \n",
    "                                 np.argmax(np.array(target_vals)[-params[\"print_step\"]:, -1], -1))\n",
    "\n",
    "        print \"loss\", losses[\"loss\"]\n",
    "        print \"matches\", losses[\"matches\"]\n",
    "\n",
    "        np.save(\"{}/{}/losses_{}.npy\".format(cifs_path, params[\"timestamp\"], i), losses)\n",
    "\n",
    "    #Save the model and the masks generated\n",
    "    if len(target_vals) % params[\"save_step\"] == 0 and len(target_vals) > 0:\n",
    "        print \"saving for {}\".format(i)\n",
    "        np.save(\"{}/{}/outputs_{}.npy\".format(cifs_path, params[\"timestamp\"], i), output_vals[-50:])\n",
    "        np.save(\"{}/{}/targets_{}.npy\".format(cifs_path, params[\"timestamp\"], i), target_vals[-50:])\n",
    "        np.save(\"{}/{}/inputs_{}.npy\".format(cifs_path, params[\"timestamp\"], i), input_vals[-50:])\n",
    "        np.save(\"{}/{}/attributes_{}.npy\".format(cifs_path, params[\"timestamp\"], i), attributes[-50:])\n",
    "\n",
    "        #Save the weights of the model - disabled because the model checkpoints are big and bulky \n",
    "        # ncomputer.save(sess, \n",
    "        #                \"{}/{}\".format(params[\"timestamp\"]), cifs_path, \n",
    "        #                \"saved_weights_{}.npy\".format(i))\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from dnc.dnc import DNC\n",
    "import dnc.utility as uf\n",
    "\n",
    "# from feedforward_controller import FeedforwardController\n",
    "from basic_recurrent_controller import BasicRecurrentController\n",
    "from focus_recurrent_controller import FocusRecurrentController\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = (5, 10)\n",
    "\n",
    "sess = None\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_sets('/tmp/tensorflow/mnist/input_data', one_hot=True)\n",
    "\n",
    "# TODO: For the DNC-controlled sliding window, just make the \"sequence input\" to the DNC be a sequence of images. Then\n",
    "# make the first step of the controller to be to apply the index window on top of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# num_labels = 2\n",
    "def make_ims(kind, size=8, splits=4):\n",
    "    if kind == \"center\":\n",
    "        Input, _, Target_Output = uf.get_center_bar_images(bsize, size=size, splits=splits, stagger=False)\n",
    "    elif kind == \"right\":\n",
    "        Input, _, Target_Output = uf.get_right_bar_images(bsize, size=size, splits=splits, stagger=False)\n",
    "    return Input, Target_Output\n",
    "\n",
    "\n",
    "if not sess is None:\n",
    "    sess.close()\n",
    "\n",
    "bsize = 1\n",
    "input_size = 64\n",
    "num_labels = 2\n",
    "sequence_length = 16\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "\n",
    "ncomputer = DNC(\n",
    "    FocusRecurrentController,\n",
    "    input_size=input_size,\n",
    "    output_size=num_labels,\n",
    "    max_sequence_length=sequence_length,\n",
    "    memory_words_num=10,\n",
    "    memory_word_size=10,\n",
    "    memory_read_heads=1,\n",
    "    batch_size=bsize\n",
    ")\n",
    "assert ncomputer.controller.has_recurrent_nn\n",
    "\n",
    "raw_outputs, memory_views = ncomputer.get_outputs()\n",
    "output = tf.argmax(raw_outputs[:, sequence_length - 1, :], 1)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(raw_outputs[:, sequence_length - 1, :], \n",
    "                                                              ncomputer.target_output_final))\n",
    "\n",
    "start = time.time()\n",
    "updt = uf.get_updt(loss)\n",
    "print time.time() - start\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "print \"initializing...\"\n",
    "sess.run(init)\n",
    "print \"initialized!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print_step = 200\n",
    "losses = []\n",
    "inputs = []\n",
    "outputs = []\n",
    "targets = []\n",
    "views = []\n",
    "raw_focuses_row = []\n",
    "raw_focuses_col = []\n",
    "focuses = []\n",
    "\n",
    "for i in tqdm(range(1000000)):\n",
    "    \n",
    "    Input, Target_Output = make_ims(\"right\")\n",
    "\n",
    "    OUT = sess.run([\n",
    "        loss,\n",
    "        output,\n",
    "        memory_views,\n",
    "        updt] + \n",
    "        ncomputer.controller.focus_row +\n",
    "        ncomputer.controller.focus_col\n",
    "        , feed_dict={\n",
    "        ncomputer.input_data: Input,\n",
    "        ncomputer.target_output_final: Target_Output,\n",
    "        ncomputer.sequence_length: sequence_length\n",
    "    })\n",
    "    l, o, v = OUT[:3]\n",
    "    fr = OUT[4:4+len(ncomputer.controller.focus_row)]\n",
    "    fc = OUT[4+len(ncomputer.controller.focus_row):]\n",
    "    pairs = zip(np.argmax(np.array(fr)[:,0,:], -1), np.argmax(np.array(fr)[:,0,:], -1))\n",
    "\n",
    "    losses.append(l)\n",
    "    inputs.append(Input)\n",
    "    outputs += list(o)\n",
    "    views.append(v)\n",
    "    targets += list(np.argmax(Target_Output, axis=-1))\n",
    "    raw_focuses_row.append(np.array(fc)[:,0,:])\n",
    "    raw_focuses_col.append(np.array(fc)[:,0,:])\n",
    "    focuses.append(pairs)\n",
    "    if len(targets) % print_step == 0 and len(targets) > 0:\n",
    "        print \"loss\", np.mean(losses[-print_step:])\n",
    "        print \"matches\", np.mean(np.array(targets[-print_step:]) == np.array(outputs[-print_step:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "focuses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.subplot(2,2,1)\n",
    "# plt.imshow(np.reshape(Input[0][0], (4,4)))\n",
    "# plt.subplot(2,2,2)\n",
    "# plt.imshow(np.reshape(Input[0][1], (4,4)))\n",
    "# plt.subplot(2,2,3)\n",
    "# plt.imshow(np.reshape(Input[0][2], (4,4)))\n",
    "# plt.subplot(2,2,4)\n",
    "# plt.imshow(np.reshape(Input[0][3], (4,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# focus_row_updater, focus_col_updater, normed_nn_output, rup = sess.run([\n",
    "#         ncomputer.controller.focus_row_updater,\n",
    "#         ncomputer.controller.focus_col_updater,\n",
    "#         ncomputer.controller.nn_output/(1e-4 + tf.reduce_sum(tf.abs(ncomputer.controller.nn_output))), \n",
    "#         tf.matmul(ncomputer.controller.nn_output/(1e-4 + tf.reduce_sum(tf.abs(ncomputer.controller.nn_output))), \n",
    "#                   ncomputer.controller.focus_row_updater)\n",
    "        \n",
    "#     ], feed_dict={\n",
    "#         ncomputer.input_data: Input,\n",
    "#         ncomputer.target_output_final: Target_Output,\n",
    "#         ncomputer.sequence_length: sequence_length\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ix = 4\n",
    "# v = views[ix]\n",
    "# print targets[ix]\n",
    "# Input = inputs[ix]\n",
    "\n",
    "# for i, w, r in zip(range(4), np.squeeze(v['write_weightings'][0]), np.squeeze(v['read_weightings'][0])):\n",
    "#     plt.subplot(2,2,i + 1)\n",
    "#     plt.plot(w, label=\"w\")\n",
    "#     plt.plot(r, label=\"r\")\n",
    "#     plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # batch_x, batch_y = mnist.train.next_batch(bsize)\n",
    "# # Input, Target_Output = get_im_sequence(batch_x, batch_y)\n",
    "# Input, _, Target_Output = make_ims(bsize, size=im_size, splits=im_splits)\n",
    "\n",
    "# l, o, v, _ = sess.run([\n",
    "#     loss,\n",
    "#     output,\n",
    "#     memory_views, \n",
    "#     updt\n",
    "# ], feed_dict={\n",
    "#     ncomputer.input_data: Input,\n",
    "#     ncomputer.target_output_final: Target_Output,\n",
    "#     ncomputer.sequence_length: sequence_length\n",
    "# })\n",
    "# o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# with tf.variable_scope(\"testing4\"): \n",
    "#     Xf2 = tf.placeholder(tf.float32, [1, 26], name=\"Xf2\")\n",
    "#     state2 = tf.placeholder(tf.float32, [1, 256], name=\"state2\")\n",
    "#     out = ncomputer.controller.run_controller_network(Xf2, state2)\n",
    "#     init = tf.global_variables_initializer()\n",
    "#     print \"initializing...\"\n",
    "#     sess.run(init)\n",
    "#     print \"initialized!\"\n",
    "#     l1_output, l2_output, l3_output, nn_output = sess.run([\n",
    "#             ncomputer.controller.l1_output,\n",
    "#             ncomputer.controller.l2_output,\n",
    "#             ncomputer.controller.l3_output, \n",
    "#             ncomputer.controller.nn_output\n",
    "#         ], feed_dict={\n",
    "#             Xf2: np.zeros((1, 26)),\n",
    "#             state2: np.random.random((1, 256))\n",
    "#         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ncomputer.save(sess, \"ckpts\", \"basic_recurrent_controller_get_lrb_images_task.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#TODO: VISUALIZE GRADIENTS AND MEMORY\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print Target_Output\n",
    "# plt.subplot(2,2,1)\n",
    "# plt.imshow(np.reshape(Input[0][0], (4,4)))\n",
    "# plt.subplot(2,2,2)\n",
    "# plt.imshow(np.reshape(Input[0][1], (4,4)))\n",
    "# plt.subplot(2,2,3)\n",
    "# plt.imshow(np.reshape(Input[0][2], (4,4)))\n",
    "# plt.subplot(2,2,4)\n",
    "# plt.imshow(np.reshape(Input[0][3], (4,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
